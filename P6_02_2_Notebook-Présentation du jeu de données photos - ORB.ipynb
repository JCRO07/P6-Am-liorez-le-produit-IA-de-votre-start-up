{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "sns.set()\n",
    "# Python program to read \n",
    "# json file \n",
    " \n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataphotos = pd.read_json('photos.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataphotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataphotos.to_csv (r'dataphotos.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import random\n",
    "\n",
    "filename = \"dataphotos.csv\" \n",
    "n = sum(1 for line in open(filename))-1  # Calculate number of rows in file\n",
    "s = n//999  # sample size of 999%\n",
    "skip = sorted(random.sample(range(1, n+1), n-s))  # n+1 to compensate for header \n",
    "dataphotospourcent = pandas.read_csv(filename, skiprows=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataphotospourcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataphotospourcent['fichiers'] = 'none'\n",
    "dataphotospourcent['img_path'] = 'none'\n",
    "dataphotospourcent['labels'] = 0\n",
    "dataphotospourcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from IPython.display import display # to display images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "dico = []\n",
    "\n",
    "listing = os.listdir(\"yelp_photos/photos/\")\n",
    "for index, row in dataphotospourcent.iterrows():         \n",
    "        for file in listing:\n",
    "            file2 = ( dataphotospourcent.at[index,'photo_id'] + \".jpg\")\n",
    "            row['fichiers'] = file2\n",
    "            dataphotospourcent.at[index,'fichiers'] = row['fichiers']\n",
    "            if file == file2 :\n",
    "                row['img_path'] = file\n",
    "                dataphotospourcent.at[index,'img_path'] = row['img_path']\n",
    "                if row['label'] == 'food':\n",
    "                    row['labels'] = 0\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'drink':\n",
    "                    row['labels'] = 1\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'outside':\n",
    "                    row['labels'] = 2\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'inside':\n",
    "                    row['labels'] = 3\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'menu':\n",
    "                    row['labels'] = 4\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                #print(\"-\"*100)\n",
    "                #print(\"Image originale\")\n",
    "                #print(\"Fichier:\" + \"yelp_photos/photos/\" + file)\n",
    "                im = Image.open(\"yelp_photos/photos/\" + file) \n",
    "                #im = im.resize((100,100))\n",
    "                #print(\"Label:\" + dataphotospourcent.at[index,'label'])\n",
    "                #print(im)\n",
    "                #display(im)\n",
    "                # Charger l'image comme matrice de pixels\n",
    "                img = np.array(Image.open(\"yelp_photos/photos/\" + file))\n",
    "                img_nparray = Image.fromarray(np.uint8(img))\n",
    "                # Générer et afficher l'histogramme\n",
    "                # Pour le normaliser : argument density=True dans plt.hist\n",
    "                # Pour avoir l'histogramme cumulé : argument cumulative=True\n",
    "                # print(\"Histogramme image originale\")\n",
    "                # n, bins, patches = plt.hist(img.flatten(), bins=range(256))\n",
    "                # plt.show()   \n",
    "                #print(\"Image filtrée\")\n",
    "                #display(im.filter(ImageFilter.ModeFilter(size=3)))\n",
    "                #print(\"Histogramme image filtrée\")\n",
    "                img2 = np.array(im.filter(ImageFilter.ModeFilter(size=3)))\n",
    "                #n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "                #plt.show()  \n",
    "                #print(\"Image égalisée\")\n",
    "                #display(im.filter(ImageFilter.ModeFilter(size=3)))\n",
    "                #print(\"Histogramme image égalisée\")\n",
    "                img3 = np.array(ImageOps.equalize(im.filter(ImageFilter.ModeFilter(size=3)), mask = None))\n",
    "                #n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "                #plt.show()    \n",
    "                \n",
    "                #print(\"Image avec les features détectées avec ORB\")\n",
    "                gray= cv2.cvtColor(img3,cv2.COLOR_BGR2GRAY)\n",
    "                orb = cv2.ORB_create()\n",
    "                kp = orb.detect(gray,None)\n",
    "                kp, des = orb.detectAndCompute(img3, None)\n",
    "                \n",
    "                #Extract keypoints from each image\n",
    "                for d in des:\n",
    "                    dico.append(d)\n",
    "                img4=cv2.drawKeypoints(gray,kp,img3)\n",
    "                im1 = Image.fromarray(np.uint8(img4))\n",
    "                #display(im1)\n",
    "                #cv2.imwrite(dataphotospourcent.at[index,'photo_id'] + \"sift_keypoints\" + \".jpg\",img4)  \n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataphotospourcent.to_csv (r'dataphotospourcent.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataphotospourcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "train_df = dataphotospourcent.drop([\"business_id\",\"caption\",\"label\",\"fichiers\"], axis=1)\n",
    "train_df = train_df.rename(columns={\"labels\": \"label\"})\n",
    "\n",
    "train_df.to_csv (r'train_csv.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"yelp_photos/photos/\"\n",
    "train = train_df\n",
    "labels = train.label.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = np.size(labels) * 10\n",
    "\n",
    "batch_size = np.size(os.listdir(img_path)) * 3\n",
    "kmeans = MiniBatchKMeans(n_clusters=k, batch_size=batch_size, verbose=1).fit(dico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger l'image sous forme d'une matrice de pixels\n",
    "img = np.array(img_nparray)\n",
    "\n",
    "# Générer le bruit gaussien de moyenne nulle et d'écart-type 7 (variance 49)\n",
    "noise = np.random.normal(0, 7, img.shape)\n",
    "display(noise)\n",
    "\n",
    "\n",
    "# Créer l'image bruitée et l'afficher\n",
    "noisy_img = Image.fromarray(np.uint8(img + noise))\n",
    "#noisy_img = Image.fromarray(img + noise).convert('L')\n",
    "#noisy_img.show()\n",
    "display(noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(noisy_img)\n",
    "display(noisy_img.filter(ImageFilter.BoxBlur(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_img2 = noisy_img.filter(ImageFilter.BoxBlur(1))\n",
    "\n",
    "img1 = np.array(noisy_img)\n",
    "img2 = np.array(noisy_img2)\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(noisy_img)\n",
    "display(ImageOps.equalize(noisy_img.filter(ImageFilter.BoxBlur(1)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(noisy_img)\n",
    "img3 = np.array(ImageOps.equalize(noisy_img.filter(ImageFilter.BoxBlur(1)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()\n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.BoxBlur(1)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.BoxBlur(1)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.BoxBlur(1)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.BoxBlur(1)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.GaussianBlur(radius=1)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.GaussianBlur(radius=1)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.GaussianBlur(radius=1)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.GaussianBlur(radius=1)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.Kernel((3, 3),(1, 1, -1, -1, 9, -1, -2, -3, -1), 1, 0)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.Kernel((3, 3),(1, 1, -1, -1, 9, -1, -2, -3, -1), 1, 0)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.Kernel((3, 3),(1, 1, -1, -1, 9, -1, -2, -3, -1), 1, 0)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.Kernel((3, 3),(1, 1, -1, -1, 9, -1, -2, -3, -1), 1, 0)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.RankFilter(1 , 0)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.RankFilter(1 , 0)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.RankFilter(1 , 0)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.RankFilter(1 , 0)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.MedianFilter(size=3)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.MedianFilter(size=3)), mask = None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.MedianFilter(size=3)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.MedianFilter(size=3)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()   \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.MinFilter(size=3)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.MinFilter(size=3)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.MinFilter(size=3)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.MinFilter(size=3)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()   \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.MaxFilter(size=3)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.MaxFilter(size=3)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.MaxFilter(size=3)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.MaxFilter(size=3)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()   \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "display(img_nparray)\n",
    "display(img_nparray.filter(ImageFilter.ModeFilter(size=3)))\n",
    "display(ImageOps.equalize(img_nparray.filter(ImageFilter.ModeFilter(size=3)), mask = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(img_nparray)\n",
    "img2 = np.array(img_nparray.filter(ImageFilter.ModeFilter(size=3)))\n",
    "img3 = np.array(ImageOps.equalize(img_nparray.filter(ImageFilter.ModeFilter(size=3)), mask = None))\n",
    "\n",
    "n, bins, patches = plt.hist(img1.flatten(), bins=range(256))\n",
    "plt.show()    \n",
    "\n",
    "n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "plt.show()   \n",
    "\n",
    "n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#img = cv2.imread('home.jpg')\n",
    "gray= cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv2.drawKeypoints(gray,kp,img)\n",
    "im1 = Image.fromarray(np.uint8(img))\n",
    "display(im1)\n",
    "#cv2.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#img = cv2.imread('home.jpg')\n",
    "gray= cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "orb = cv2.ORB_create()\n",
    "kp = orb.detect(gray,None)\n",
    "img=cv2.drawKeypoints(gray,kp,img)\n",
    "im1 = Image.fromarray(np.uint8(img))\n",
    "display(im1)\n",
    "#cv2.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from IPython.display import display # to display images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "dico = []\n",
    "kmeans.verbose = False\n",
    "histo_list = []\n",
    "\n",
    "listing = os.listdir(\"yelp_photos/photos/\")\n",
    "for index, row in dataphotospourcent.iterrows():         \n",
    "        for file in listing:\n",
    "            file2 = ( dataphotospourcent.at[index,'photo_id'] + \".jpg\")\n",
    "            row['fichiers'] = file2\n",
    "            dataphotospourcent.at[index,'fichiers'] = row['fichiers']\n",
    "            if file == file2 :\n",
    "                row['img_path'] = file\n",
    "                dataphotospourcent.at[index,'img_path'] = row['img_path']\n",
    "                if row['label'] == 'food':\n",
    "                    row['labels'] = 0\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'drink':\n",
    "                    row['labels'] = 1\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'outside':\n",
    "                    row['labels'] = 2\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'inside':\n",
    "                    row['labels'] = 3\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                if row['label'] == 'menu':\n",
    "                    row['labels'] = 4\n",
    "                    dataphotospourcent.at[index,'labels'] = row['labels']  \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                print(\"-\"*100)\n",
    "                print(\"Image originale\")\n",
    "                print(\"Fichier:\" + \"yelp_photos/photos/\" + file)\n",
    "                im = Image.open(\"yelp_photos/photos/\" + file) \n",
    "                #im = im.resize((100,100))\n",
    "                print(\"Label:\" + dataphotospourcent.at[index,'label'])\n",
    "                print(im)\n",
    "                display(im)\n",
    "                # Charger l'image comme matrice de pixels\n",
    "                img = np.array(Image.open(\"yelp_photos/photos/\" + file))\n",
    "                img_nparray = Image.fromarray(np.uint8(img))\n",
    "                # Générer et afficher l'histogramme\n",
    "                # Pour le normaliser : argument density=True dans plt.hist\n",
    "                # Pour avoir l'histogramme cumulé : argument cumulative=True\n",
    "                print(\"Histogramme image originale\")\n",
    "                n, bins, patches = plt.hist(img.flatten(), bins=range(256))\n",
    "                plt.show()   \n",
    "                print(\"Image filtrée\")\n",
    "                display(im.filter(ImageFilter.ModeFilter(size=3)))\n",
    "                print(\"Histogramme image filtrée\")\n",
    "                img2 = np.array(im.filter(ImageFilter.ModeFilter(size=3)))\n",
    "                n, bins, patches = plt.hist(img2.flatten(), bins=range(256))\n",
    "                plt.show()  \n",
    "                print(\"Image égalisée\")\n",
    "                display(im.filter(ImageFilter.ModeFilter(size=3)))\n",
    "                print(\"Histogramme image égalisée\")\n",
    "                img3 = np.array(ImageOps.equalize(im.filter(ImageFilter.ModeFilter(size=3)), mask = None))\n",
    "                n, bins, patches = plt.hist(img3.flatten(), bins=range(256))\n",
    "                plt.show()    \n",
    "                \n",
    "                print(\"Image avec les features détectées avec ORB\")\n",
    "                gray= cv2.cvtColor(img3,cv2.COLOR_BGR2GRAY)\n",
    "                orb = cv2.ORB_create()\n",
    "                kp = orb.detect(gray,None)\n",
    "                kp, des = orb.detectAndCompute(img3, None)\n",
    "                \n",
    "                #Extract keypoints from each image\n",
    "                for d in des:\n",
    "                    dico.append(d)\n",
    "                \n",
    "                #Creation of the histograms\n",
    "                histo = np.zeros(k)\n",
    "                nkp = np.size(kp)\n",
    "                \n",
    "                for d in des:\n",
    "                    idx = kmeans.predict([d])\n",
    "                    histo[idx] += 1/nkp # Because we need normalized histograms, I prefere to add 1/nkp directly\n",
    "\n",
    "                histo_list.append(histo)                    \n",
    "    \n",
    "                img4=cv2.drawKeypoints(gray,kp,img3)\n",
    "                im1 = Image.fromarray(np.uint8(img4))\n",
    "                display(im1)\n",
    "                #cv2.imwrite(dataphotospourcent.at[index,'photo_id'] + \"orb_keypoints\" + \".jpg\",img4)  \n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train.label.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(histo_list)\n",
    "y = []\n",
    "\n",
    "# It's a way to convert labels name into an integer\n",
    "for s in train.label:\n",
    "    y.append(np.min(np.nonzero(labels == s)))\n",
    "    \n",
    "X, y = make_classification(n_samples=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(verbose=True, max_iter=600000)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy MLP classifier features obtenue avec ORB')\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
